# Bigdata
<br><strong>Unidad 2</strong>
<p align="center">
<br><strong>Tecnológico Nacional de México</strong>
<br><strong>Instituto Tecnológico de Tijuana</strong>
<br><strong>Subdirección académica</strong>
<br><strong>Departamento de Sistemas y Computación</strong>
<br><strong>Semestre: ENERO - JUNIO 2020</strong>
<br><strong>Ingeniería en Tecnologías de la Información y Comunicaciones</strong>
<br><strong>Ingeniería Informatica</strong>
<br><strong>Materia: Datos Masivos</strong>
<br><strong>Unidad: 2</strong>
<br><strong>Dorado Aguilus Ruben #15210328</strong>
   <br><strong>Mejia Manriquez Rocio #14212336</strong>
<br><strong>Docente: Dr. Jose Christian Romero Hernandez</strong>
</p>

<li>
   <li>
<li> Unidad2
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2/Tareas ">TAREAS</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/regrecion.scala  ">Regrecion linial</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/PIPELINE ">Pipeline</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/CONFUSION%20MATRIX ">Confusion matrix</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/Algorithms%20in%20Machine%20Learning ">Algoritmos M.L</a>

=======
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad1/Tareas ">Unidad: 1</a>
<li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad1/Tareas ">TAREAS</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad1/Tareas/Practica1.scala  ">Practica 1</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad1/Tareas/Practica2.scala ">Practica 2</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad1/Tareas/Pearson%20correlation.txt ">Pearson</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad1/Tareas/fibonacci.scala ">Fibonacci</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad1/Tareas/TareaGroupBy.scala">Grup By</a>
<li> master
<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2">EXAMEN</a>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2/Examen-iris">Examen-iris</a>

<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2/Exposiciones">Expociciones</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/LSVM.scala">Linear support vector machine</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/LR.scala">Logistic Regression</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/DT.scala">Decision Tree Classifier</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/MLP.scala">Multilayer perceptron classifier</a>


<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2 ">Unidad: 2</a>
<li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2/Tareas ">TAREAS</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/regrecion.scala  ">Regrecion linial</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/PIPELINE ">Pipeline</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/CONFUSION%20MATRIX ">Confusion matrix</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Tareas/Algorithms%20in%20Machine%20Learning ">Algoritmos M.L</a>

<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2">EXAMEN</a>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2/Examen-iris">Examen-iris</a>

<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad2/Exposiciones">Expociciones</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/LSVM.scala">Linear support vector machine</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/LR.scala">Logistic Regression</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/DT.scala">Decision Tree Classifier</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Exposiciones/MLP.scala">Multilayer perceptron classifier</a>

<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad3 ">Unidad: 3</a>
<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad3/Examen">EXAMEN</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad3/Examen/ExamenU3.scala">Wholesale customers</a>

   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad4 ">Unidad: 4</a>
<li>
   <li>
<li><a href="https://github.com/rubens084/Bigdata/tree/Unidad4/Proyecto">Proyecto</a>
<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad4/Proyecto/Full.scala">Comparacion</a>



<li>
<li>
<li>This document contains exercises and practices of the kind of massive data taught in the technology of 
<li>Tijuana taught by Dr. Cristian Romero.
<li>the practices are taught in Spark in scala documents with a staggered learning system.
<li>
   <li>

<li><a href="https://github.com/rubens084/Bigdata/blob/Unidad2/Examen-iris/Examen.scala">Examen</a>
<li>Agregamos las lbrerias necesarias para trabajar con el algortimo Multilayer Perceptron.
<li>El clasificador de perceptrón multicapa (MLPC) es un clasificador basado en la red neuronal
<li>artificial de alimentación directa. MLPC consta de múltiples capas de nodos. Cada capa está 
<li>completamente conectada a la siguiente capa en la red.
<li>import org.apache.spark.ml.classification.MultilayerPerceptronClassifier
<li>Clase pública MulticlassClassificationEvaluatorextiende el evaluadorimplementa DefaultParamsWritable
<li>Evaluador para clasificación multiclase, que espera dos columnas de entrada: predicción y etiqueta.
<li>import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator

<li>Del data set Iris.cvs, elaborar la limpieza de datos necesaria por medio de un scrip en scala spark, 
<li>impportamos las librerias necesarias para la limpieza.
<li>Un transformador de características que combina varias columnas en una columna vectorial.
<li>Esto requiere una pasada sobre todo el conjunto de datos. En caso de que necesitemos inferir 
<li>longitudes de columna a partir de los datos, requerimos una llamada adicional al 'primer' método 
<li>de conjunto de datos, consulte el parámetro 'handleInvalid'.
<li>import org.apache.spark.ml.feature.VectorAssembler
<li>convierte una sola columna en una columna de índice (similar a una columna de factor en R)
<li>import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer}
<li>Métodos de fábrica para trabajar con vectores. Tenga en cuenta que los vectores densos simplemente 
<li>se representan como objetos de matriz NumPy, por lo que no es necesario convertirlos para usarlos en 
<li>MLlib. Para vectores dispersos, los métodos de fábrica en esta clase crean un tipo compatible con MLlib,
<li>o los usuarios pueden pasar los vectores de columna scipy.sparse de SciPy.
<li>import org.apache.spark.ml.linalg.Vectors
<li>
<li>Se cargan los datos del dataser iris.csv en la variable "data"
<li>val data  = spark.read.option("header","true").option("inferSchema", "true").format("csv").load("iris.csv")
<li>Se eliminan los campos null suelta las filas que tienen nulo solo en la columna onlyColumnInOneColumnDataFrame.
<li>val dataClean = data.na.drop()
<li>muestra el nombre de las columnas
<li>data.schema.names
<li>Vemos el esquema para comprobar que todos los valores estan calsificados correctamente en el dataset
<li>data.printSchema()
<li>se muestran los primeros 5 valores de la lista con sus datos en una tabla
<li>data.show(5)
<li>La instrucción DESCRIBE FUNCTION devuelve la información básica de metadatos de una función existente. 
<li>La información de metadatos incluye el nombre de la función, la clase de implementación y los detalles de uso. 
<li>Si se especifica la opción EXTENDED opcional, la información básica de metadatos se devuelve junto con la información de uso extendida.
<li>data.describe().show

<li>Se declara un vector que se transforma los datos a la variable "features" Esta sección cubre algoritmos para trabajar con características, <li>divididas aproximadamente en estos grupos:
<li>Extracción: extracción de características de datos "en bruto", Transformación: escalar, convertir o modificar características
<li>Selección: seleccionar un subconjunto de un conjunto más amplio de características
<li>val vectorFeatures = (new VectorAssembler().setInputCols(Array("sepal_length","sepal_width", <li>"petal_length","petal_width")).setOutputCol("features"))
<li>
<li>
<li>Se transforman los features usando el dataframe
<li>val features = vectorFeatures.transform(dataClean)
<li>
<li>Se declara un "StringIndexer" que transformada los datos en "species" en datos numericos 
<li>val speciesIndexer = new StringIndexer().setInputCol("species").setOutputCol("label")
<li>
<li>Ajustamos las especies indexadas con el vector features
<li>val dataIndexed = speciesIndexer.fit(features).transform(features)
<li>
<li> Con la variable "splits" hacemos un corte de forma aleatoria se utiliza el 60%
<li>del dataset en training y 40% en test, se utiliza un corte random con una semilla de 1234
<li>val splits = dataIndexed.randomSplit(Array(0.6, 0.4), seed = 1234L)
<li>
<li>Se declara la variable "train" la cual tendra el 60% de los datos en la posicion
<li>(0) que contiene el 60%
<li>val train = splits(0)
<li>
<li>Se declara la variable "test" la cual tendra el 40% de los datosen la pocicion (1)
<li>con el sobrante 40% del data set
<li>val test = splits(1)
<li>
<li>Se establece la configuracion de las capas para el modelo de redes neuronales artificiales
<li>val layers = Array[Int](4, 2, 2, 3)
<li>
<li>Se configura el entrenador del algoritmo Multilayer con sus respectivos parametros
<li>val trainer = new MultilayerPerceptronClassifier().setLayers(layers).setBlockSize(128).setSeed(1234L).setMaxIter(100)
<li>
<li>Se entrena el modelo con los datos de entrenamiento
<li>val model = trainer.fit(train)
<li>
<li>Se prueban ya entrenado el modelo
<li>val result = model.transform(test)
<li>
<li>Se selecciona la prediccion y la etiqueta que seran guardado en la variable 
<li>val predictionAndLabels = result.select("prediction", "label")
<li>
<li>Se muestran algunos datos 
<li>predictionAndLabels.show()
<li>
<li>Se ejecuta la estimacion de la precision del modelo
<li>val evaluator = new MulticlassClassificationEvaluator().setLabelCol("label").setPredictionCol("prediction").setMetricName("accuracy")
<li>val accuracy = evaluator.evaluate(predictionAndLabels)
<li>
<li>Se imprime el error del modelo
<li>println(s"Test Error = ${(1.0 - accuracy)}")



